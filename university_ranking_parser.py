# DEPRECATED: This script was used to initially parse ranking.html
# The data has been extracted to universities.json
# This file is kept for reference only
#!/usr/bin/env python3
"""
University Ranking Parser

HTML íŒŒì¼ì—ì„œ ëŒ€í•™êµ ì´ë¦„ê³¼ ë§í¬ë¥¼ ì¶”ì¶œí•˜ì—¬ JSON íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import json
import re
from bs4 import BeautifulSoup
from pathlib import Path


class UniversityRankingParser:
    """ëŒ€í•™êµ ë­í‚¹ HTMLì„ íŒŒì‹±í•˜ì—¬ ëŒ€í•™êµ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, html_file_path: str):
        """
        HTML íŒŒì¼ ê²½ë¡œë¡œ íŒŒì„œ ì´ˆê¸°í™”
        
        Args:
            html_file_path: ranking.html íŒŒì¼ì˜ ê²½ë¡œ
        """
        self.html_file_path = Path(html_file_path)
        self.universities = []
    
    def parse_html(self) -> list:
        """
        HTML íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ëŒ€í•™êµ ì •ë³´ ì¶”ì¶œ
        
        Returns:
            list: ëŒ€í•™êµ ì •ë³´ê°€ ë‹´ê¸´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
                 [{"name": "Princeton University", "link": "/best-colleges/princeton-university-2627"}, ...]
        """
        try:
            # HTML íŒŒì¼ ì½ê¸°
            with open(self.html_file_path, 'r', encoding='utf-8') as file:
                html_content = file.read()
            
            # Beautiful Soupë¡œ íŒŒì‹±
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # ëŒ€í•™êµ ë¦¬ìŠ¤íŠ¸ ì•„ì´í…œ ì°¾ê¸°
            university_items = soup.find_all('li', class_='item-list__ListItemStyled-sc-18yjqdy-1')
            
            print(f"Found {len(university_items)} university items")
            
            for item in university_items:
                university_info = self._extract_university_info(item)
                if university_info:
                    self.universities.append(university_info)
            
            print(f"Successfully parsed {len(self.universities)} universities")
            return self.universities
            
        except FileNotFoundError:
            print(f"Error: HTML file not found at {self.html_file_path}")
            return []
        except Exception as e:
            print(f"Error parsing HTML: {e}")
            return []
    
    def _extract_university_info(self, item) -> dict:
        """
        ê°œë³„ ëŒ€í•™êµ ì•„ì´í…œì—ì„œ ì´ë¦„ê³¼ ë§í¬ ì¶”ì¶œ
        
        Args:
            item: BeautifulSoup element (li íƒœê·¸)
            
        Returns:
            dict: {"name": "University Name", "link": "/best-colleges/university-name-id"}
        """
        try:
            # ë°©ë²• 1: name ì†ì„±ì—ì„œ ëŒ€í•™êµ ì´ë¦„ ì°¾ê¸°
            card_container = item.find('div', attrs={'name': True})
            if card_container:
                university_name = card_container.get('name')
            else:
                # ë°©ë²• 2: h3 íƒœê·¸ì—ì„œ ëŒ€í•™êµ ì´ë¦„ ì°¾ê¸°
                h3_tag = item.find('h3')
                if h3_tag:
                    university_name = h3_tag.get_text().strip()
                else:
                    return None
            
            # ëŒ€í•™êµ ë§í¬ ì°¾ê¸° - /best-colleges/ë¡œ ì‹œì‘í•˜ëŠ” href
            link_element = item.find('a', href=re.compile(r'^/best-colleges/'))
            if not link_element:
                return None
            
            university_link = link_element.get('href')
            
            # URLì—ì„œ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì œê±° (ì˜ˆ: ?photo-strip)
            university_link = university_link.split('?')[0]
            
            return {
                "name": university_name,
                "link": university_link
            }
            
        except Exception as e:
            print(f"Error extracting university info: {e}")
            return None
    
    def save_to_json(self, output_file: str = "universities.json") -> bool:
        """
        ì¶”ì¶œëœ ëŒ€í•™êµ ì •ë³´ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            output_file: ì €ì¥í•  JSON íŒŒì¼ëª…
            
        Returns:
            bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        try:
            output_path = Path(output_file)
            
            with open(output_path, 'w', encoding='utf-8') as file:
                json.dump(self.universities, file, indent=2, ensure_ascii=False)
            
            print(f"Successfully saved {len(self.universities)} universities to {output_path}")
            return True
            
        except Exception as e:
            print(f"Error saving to JSON: {e}")
            return False
    
    def print_universities(self):
        """ì¶”ì¶œëœ ëŒ€í•™êµ ì •ë³´ë¥¼ ì½˜ì†”ì— ì¶œë ¥"""
        if not self.universities:
            print("No universities found")
            return
        
        print(f"\n=== Extracted Universities ({len(self.universities)}) ===")
        for i, university in enumerate(self.universities, 1):
            print(f"{i:2d}. {university['name']}")
            print(f"    Link: {university['link']}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # HTML íŒŒì¼ ê²½ë¡œ
    html_file = "ranking.html"
    
    # íŒŒì„œ ìƒì„± ë° ì‹¤í–‰
    parser = UniversityRankingParser(html_file)
    
    # HTML íŒŒì‹±
    universities = parser.parse_html()
    
    if universities:
        # ê²°ê³¼ ì¶œë ¥
        parser.print_universities()
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        parser.save_to_json("universities.json")
        
        print(f"\nâœ… Successfully processed {len(universities)} universities")
        print("ğŸ“ Data saved to universities.json")
    else:
        print("âŒ No universities found or error occurred")


if __name__ == "__main__":
    main()
